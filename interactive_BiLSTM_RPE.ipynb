{"cells":[{"cell_type":"markdown","source":["# Instructions\n","Run the notebook except the last cell to load all the packages, models and functions. Then, provide an input when promtped to the `test_sentence` string variable in the last cell of the notebook. Your sentence must contain tags to indicate the entities of the relation you would like the model to predict. For example your sentence may be: `'The <e1>bottle</e1> is filled with <e2>water</e2>.'`. The `'<e1>'` and `'</e1>'` tags indicate the first entity, `'bottle'`, and the `'<e2>'` and `'</e2>'` tags indicate the second entity, `'water'`."],"metadata":{"id":"DANJo57fBHOh"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1385,"status":"ok","timestamp":1741357778802,"user":{"displayName":"Joshwin Sundarraj","userId":"12660709160484617329"},"user_tz":0},"id":"8HCLiMkQWKNG","outputId":"42a059a0-c650-45a7-8463-ba963b99f0ff"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import nltk\n","import re\n","import math\n","import json\n","import pickle\n","import shutil\n","import os\n","import tensorflow as tf\n","\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.pipeline import make_pipeline\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.pipeline import Pipeline\n","from sklearn.svm import SVC, LinearSVC, NuSVC\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n","from sklearn.metrics import precision_score, recall_score\n","\n","from sklearn.model_selection import KFold\n","\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dropout, Dense\n","from tensorflow.keras.layers import LSTM\n","from tensorflow.keras.layers import Embedding, Bidirectional, SpatialDropout1D\n","from tensorflow.keras.layers import Concatenate, Input\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ReduceLROnPlateau\n","\n","import gensim.downloader as api\n","\n","\n","from google.colab import drive\n","\n","path = '/content/drive/MyDrive/Text_Mining/BILSTM/'\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["## **Data Pre-processing**"],"metadata":{"id":"VUcxSKXInvhZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"RY1BemwIjwUN"},"outputs":[],"source":["# method to one hot encode the relation label\n","def one_hot_encode_relations(relation_label, num_classes=19):\n","  one_hot = np.zeros(num_classes)\n","  one_hot[relation_label] = 1\n","  return one_hot\n","\n","# method to produce relative postion encodings for sentences\n","def get_relative_positions(sentence):\n","\n","  tokens = re.findall(r'<e\\d+>|</e\\d+>|\\S+', sentence)\n","\n","  # Identify entity indices and words inside tags\n","  e1_index = None\n","  e2_index = None\n","  inside_e1 = False\n","  inside_e2 = False\n","\n","  for i, token in enumerate(tokens):\n","      if token == \"<e1>\":\n","          e1_index = i  # Start of entity\n","          inside_e1 = True\n","      elif token == \"</e1>\":\n","          inside_e1 = False\n","      elif token == \"<e2>\":\n","          e2_index = i  # Start of entity\n","          inside_e2 = True\n","      elif token == \"</e2>\":\n","          inside_e2 = False\n","\n","  # make sure valid indices were found in the sentence\n","  if e1_index is None or e2_index is None:\n","      raise ValueError(\"Both <e1> and <e2> entities must be present.\")\n","\n","  pos1 = []\n","  pos2 = []\n","  inside_e1 = False\n","  inside_e2 = False\n","\n","  # calculate the relative positions based on tokens\n","  for i, token in enumerate(tokens):\n","      if token == \"<e1>\":\n","          pos1.append(-1)\n","          inside_e1 = True\n","      elif token == \"</e1>\":\n","          pos1.append(1)\n","          inside_e1 = False\n","      elif inside_e1:\n","          pos1.append(0)\n","      elif pos1 and pos1[-1] >= 0:\n","          pos1.append(pos1[-1] + 1)\n","      else:\n","          pos1.append(i - e1_index)\n","\n","      if token == \"<e2>\":\n","          pos2.append(-1)\n","          inside_e2 = True\n","      elif token == \"</e2>\":\n","          pos2.append(1)\n","          inside_e2 = False\n","      elif inside_e2:\n","          pos2.append(0)\n","      elif pos2 and pos2[-1] >= 0:\n","          pos2.append(pos2[-1] + 1)\n","      else:\n","          pos2.append(i - e2_index)\n","\n","  return tokens, pos1, pos2\n","\n","# method to produce token and positional encodings for sentences\n","def preprocess_dataset(dataset, tokenizer, max_seq_length=128, num_classes=19):\n","\n","  X_word, X_pos1, X_pos2, Y = [], [], [], []\n","\n","  for _, sample in dataset.iterrows():\n","    sentence = sample['sentence']\n","    relation = sample['relation']\n","\n","    # tokens, entity1_pos, entity2_pos, close_entity1_pos, close_entity2_pos = preprocess_sentence(sentence)\n","\n","    tokens, pos1, pos2 = get_relative_positions(sentence)\n","\n","    token_ids = tokenizer.texts_to_sequences([tokens])[0] #convert to indices?\n","\n","\n","    # pos1, pos2 = compute_relative_positions(len(token_ids), entity1_pos, entity2_pos, close_entity1_pos, close_entity2_pos)\n","\n","    token_ids = pad_sequences([token_ids], maxlen=max_seq_length, padding='post')[0]\n","    pos1 = pad_sequences([pos1], maxlen=max_seq_length, padding='post')[0]\n","    pos2 = pad_sequences([pos2], maxlen=max_seq_length, padding='post')[0]\n","\n","\n","    relation_one_hot = one_hot_encode_relations(relation, num_classes)\n","\n","    X_word.append(token_ids)\n","    X_pos1.append(pos1)\n","    X_pos2.append(pos2)\n","    Y.append(relation_one_hot)\n","\n","  return np.array(X_word), np.array(X_pos1), np.array(X_pos2), np.array(Y)\n","\n","# method to delimit entity markers with spaces for proper tokenization later on\n","def replace_entity_markers(text):\n","    text = text.replace(\"<e1>\", \" <e1> \").replace(\"</e1>\", \" </e1> \")\n","    text = text.replace(\"<e2>\", \" <e2> \").replace(\"</e2>\", \" </e2> \")\n","    return text"]},{"cell_type":"markdown","source":["## **Interact with Model**"],"metadata":{"id":"iXReoJuyqKRn"}},{"cell_type":"code","source":["class_label_mapping = {\n","    0: \"Cause-Effect(e1,e2)\", 1: \"Cause-Effect(e2,e1)\",\n","    2: \"Component-Whole(e1,e2)\", 3: \"Component-Whole(e2,e1)\",\n","    4: \"Content-Container(e1,e2)\", 5: \"Content-Container(e2,e1)\",\n","    6: \"Entity-Destination(e1,e2)\", 7: \"Entity-Destination(e2,e1)\",\n","    8: \"Entity-Origin(e1,e2)\", 9: \"Entity-Origin(e2,e1)\",\n","    10: \"Instrument-Agency(e1,e2)\", 11: \"Instrument-Agency(e2,e1)\",\n","    12: \"Member-Collection(e1,e2)\", 13: \"Member-Collection(e2,e1)\",\n","    14: \"Message-Topic(e1,e2)\", 15: \"Message-Topic(e2,e1)\",\n","    16: \"Product-Producer(e1,e2)\", 17: \"Product-Producer(e2,e1)\",\n","    18: \"Other\"\n","}\n","\n","def load_tokenizer(tokenizer_path):\n","    with open(tokenizer_path, 'rb') as handle:\n","        tokenizer = pickle.load(handle)\n","    return tokenizer\n","\n","def load_model(model_path):\n","    model = tf.keras.models.load_model(model_path)\n","    return model\n","\n","def sentence__relation_prediction(sentence, tokenizer, model, max_seq_length=256):\n","\n","  sentence = replace_entity_markers(sentence)\n","\n","  words = tokenizer.word_index\n","  vocab_size = len(words) + 1\n","  print(vocab_size)\n","\n","  sentence_df = pd.DataFrame([[sentence, 18]], columns=[\"sentence\", \"relation\"])\n","\n","  tokenized_sentence, e1_pos_encoding, e2_pos_encoding, _ = preprocess_dataset(sentence_df, tokenizer, max_seq_length)\n","\n","  y_pred_prob = model.predict([tokenized_sentence, e1_pos_encoding, e2_pos_encoding])\n","\n","  predicted_class = np.argmax(y_pred_prob, axis=1)[0]\n","\n","  predicted_relation = class_label_mapping.get(predicted_class)\n","\n","  return predicted_relation"],"metadata":{"id":"VC8ZfvaRbZ22"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_model = load_model(path + 'models/best_bilstm_model_75.keras')\n","tokenizer = load_tokenizer(path + 'models/best_bilstm_tokenizer_75.pickle')"],"metadata":{"id":"CZTS-aSk-5MW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_sentence = 'The <e1>bottle</e1> was filled with <e2>water</e2> and placed on the table.'\n","predicted_relation = sentence__relation_prediction(test_sentence, tokenizer, best_model)\n","print(predicted_relation)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cKDBh5ZRjstZ","executionInfo":{"status":"ok","timestamp":1741357811634,"user_tz":0,"elapsed":2798,"user":{"displayName":"Joshwin Sundarraj","userId":"12660709160484617329"}},"outputId":"fd7f47dc-b1c7-4b9d-dbef-0cd18d80b975"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["19572\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n","Content-Container(e2,e1)\n"]}]},{"cell_type":"code","source":["test_sentence = input(\"Please Enter a sentence with two entities in the format provided in the previous cell: \")\n","predicted_relation = sentence__relation_prediction(test_sentence, tokenizer, best_model)\n","print(predicted_relation)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HoiN7QKyqvtp","executionInfo":{"status":"ok","timestamp":1741357814981,"user_tz":0,"elapsed":3346,"user":{"displayName":"Joshwin Sundarraj","userId":"12660709160484617329"}},"outputId":"d2a4889c-6361-4966-c9c6-97c848c08091"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Please Enter a sentence with two entities in the format provided in the previous cell: The <e1>bottle</e1> was filled with <e2>water</e2> and placed on the table.\n","19572\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","Content-Container(e2,e1)\n"]}]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}